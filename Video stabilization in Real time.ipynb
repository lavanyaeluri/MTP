{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "def mask_my_frame(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    height, width = image.shape[:2]\n",
    "    polygons = np.array([[(20, 50), (20, height-50), (width-20, height-50), (width-20, 50)]])\n",
    "    mask = np.zeros_like(gray)\n",
    "    cv2.fillPoly(mask, polygons, 255)\n",
    "    masked_image = cv2.bitwise_or(image, image, mask=mask)\n",
    "    # masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def stabilize(frame):\n",
    "    global frame_queue, frame_queue_indexes, previous_gray, previous_keypoints, path, smoothed_path, frame_transforms_smoothed, frame_height, frame_width\n",
    "\n",
    "    if frame is None:\n",
    "        return\n",
    "\n",
    "    if not frame_queue:\t\n",
    "        previous_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        previous_gray = clahe.apply(previous_gray)\n",
    "        # cv2.imshow(\"gray\", previous_gray)\n",
    "        previous_keypoints = cv2.goodFeaturesToTrack(previous_gray, maxCorners=200, qualityLevel=0.05, minDistance=30.0, blockSize=3 , mask=None, useHarrisDetector=False, k=0.04) #track features using GFTT\n",
    "        frame_height, frame_width = frame.shape[:2]\n",
    "        frame_queue.append(frame)\n",
    "        frame_queue_indexes.append(0)\n",
    "        previous_gray = previous_gray[:]\n",
    "\n",
    "    elif frame_queue_indexes[-1] <= 24:\n",
    "        frame_queue.append(frame)\n",
    "        frame_queue_indexes.append(frame_queue_indexes[-1]+1)\n",
    "        frame_transform = generate_transformations()\n",
    "        if frame_queue_indexes[-1] == 24:\n",
    "            for i in range(3):\n",
    "                smoothed_path[:,i] = box_filter_convolve((path[:,i]), window_size=25)\n",
    "            deviation = smoothed_path - path\n",
    "            frame_transforms_smoothed = frame_transform + deviation\n",
    "\n",
    "    else:\n",
    "        frame_queue.append(frame)\n",
    "        frame_queue_indexes.append(frame_queue_indexes[-1]+1)\n",
    "        # print(frame_queue_indexes)\n",
    "        frame_transform = generate_transformations()\n",
    "\n",
    "        for i in range(3):\n",
    "            smoothed_path[:,i] = box_filter_convolve((path[:,i]), window_size=25)\n",
    "\n",
    "        deviation = smoothed_path - path\n",
    "        frame_transforms_smoothed = frame_transform + deviation\n",
    "\n",
    "        return apply_transformations()\n",
    "\n",
    "    return frame \n",
    "\n",
    "\n",
    "#Moving average filter used for smoothing the data \n",
    "def box_filter_convolve(path, window_size):\n",
    "    box_filter = np.ones(25)/25\n",
    "    path_padded = np.pad(path, (window_size, window_size), 'mean')\n",
    "    path_smoothed = np.convolve(path_padded, box_filter, mode='same')\n",
    "    path_smoothed = path_smoothed[window_size:-window_size]\n",
    "    # assert path.shape == path_smoothed.shape\n",
    "    return path_smoothed\n",
    "\n",
    "\n",
    "# Estimating Rigid Transformations\n",
    "def generate_transformations():\n",
    "\n",
    "    global frame_queue, previous_gray, previous_keypoints, path, smoothed_path\n",
    "    frame_gray = cv2.cvtColor(frame_queue[-1], cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = clahe.apply(frame_gray)\n",
    "\n",
    "    #optical flow using Lucas-Kanade differential method\n",
    "    curr_kps, status, error = cv2.calcOpticalFlowPyrLK(previous_gray, frame_gray, previous_keypoints, None)\n",
    "    valid_curr_kps = curr_kps[status==1] \n",
    "    valid_previous_keypoints = previous_keypoints[status==1] \n",
    "    # Rigid Transformation\n",
    "    transformation = cv2.estimateRigidTransform(valid_previous_keypoints,valid_curr_kps, False)\n",
    "\n",
    "    if not(transformation is None):\n",
    "        # pevious_2_current translation in x direction\n",
    "        dx = transformation[0, 2]\n",
    "        # pevious_2_current translation in y direction\n",
    "        dy = transformation[1, 2]\n",
    "        # pevious_2_current rotation in angle\n",
    "        da = np.arctan2(transformation[1, 0], transformation[0, 0])\n",
    "    else:\n",
    "        dx = dy = da = 0\n",
    "\n",
    "    transforms.append([dx, dy, da])\n",
    "\n",
    "    frame_transform = np.array(transforms, dtype='float32')\n",
    "    #cumulative-sum\n",
    "    path = np.cumsum(frame_transform, axis=0)\n",
    "    smoothed_path=np.copy(path)\n",
    "    # shi- Tomasi corner detection\n",
    "    previous_keypoints = cv2.goodFeaturesToTrack(frame_gray, maxCorners=200, qualityLevel=0.05, minDistance=30.0, blockSize=3 , mask=None, useHarrisDetector=False, k=0.04)\n",
    "    previous_gray = frame_gray[:]\n",
    "\n",
    "    return frame_transform\n",
    "\n",
    "def apply_transformations():\n",
    "    global frame_queue, frame_queue_indexes, frame_height, frame_width, frame_transforms_smoothed\n",
    "    queue_frame = frame_queue.popleft()\n",
    "    queue_frame_index = frame_queue_indexes.popleft()\n",
    "    bordered_frame = cv2.copyMakeBorder(queue_frame, top=0, bottom=0, left=0, right=0, borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    alpha_bordered_frame = cv2.cvtColor(bordered_frame, cv2.COLOR_BGR2BGRA)\n",
    "    alpha_bordered_frame[:, :, 3] = 0 \n",
    "    alpha_bordered_frame[0:0 + frame_height, 0:0 + frame_width, 3] = 255\n",
    "\n",
    "    dx = frame_transforms_smoothed[queue_frame_index,0]\n",
    "    dy = frame_transforms_smoothed[queue_frame_index,1]\n",
    "    da = frame_transforms_smoothed[queue_frame_index,2]\n",
    "\n",
    "    #2x3 transformation matrix from extracted transformations\n",
    "    queue_frame_transform = np.zeros((2,3), np.float32)\n",
    "    queue_frame_transform[0,0] = np.cos(da)\n",
    "    queue_frame_transform[0,1] = -np.sin(da)\n",
    "    queue_frame_transform[1,0] = np.sin(da)\n",
    "    queue_frame_transform[1,1] = np.cos(da)\n",
    "    queue_frame_transform[0,2] = dx\n",
    "    queue_frame_transform[1,2] = dy\n",
    "\n",
    "    frame_wrapped = cv2.warpAffine(alpha_bordered_frame, queue_frame_transform, alpha_bordered_frame.shape[:2][::-1], borderMode=cv2.BORDER_CONSTANT)\n",
    "    # cv2.imshow(\"wrap\",frame_wrapped)\n",
    "    #drop alpha channel\n",
    "    frame_stabilized = frame_wrapped[:, :, :3]\n",
    "    return frame_stabilized\n",
    "\n",
    "\n",
    "#Capturing the video using the object video capture \n",
    "cap = cv2.VideoCapture(\"C:/Users/CG-DTE/Downloads/Mtech 1st sem reference books/M.Tech project/shaky.mp4\")\n",
    "\n",
    "#Definig queue of length 25 to store the last 25 frames\n",
    "frame_queue = deque(maxlen=25)\n",
    "frame_queue_indexes = deque(maxlen=25)\n",
    "\n",
    "\n",
    "# It is used to improve contrast in images(CLAHE- contrast limited adaptive histogram equalization)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "\n",
    "smoothed_path = None\n",
    "path = None\n",
    "transforms = []\n",
    "frame_transforms_smoothed = None \n",
    "previous_gray = None \n",
    "previous_keypoints = None \n",
    "frame_height, frame_width = (0, 0)\n",
    "\n",
    "\n",
    "#Main function \n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        #Resize the frame with width 640 and height 360\n",
    "        frame = cv2.resize(frame, (640, 360), interpolation = cv2.INTER_LINEAR) \n",
    "        # calling the function stabilize(frame)\n",
    "        stabilized_frame = mask_my_frame(stabilize(frame))\n",
    "        #Displaying the frames\n",
    "        cv2.imshow(\"After\", stabilized_frame)\n",
    "        cv2.imshow(\"Before\", mask_my_frame(frame))\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else: break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
